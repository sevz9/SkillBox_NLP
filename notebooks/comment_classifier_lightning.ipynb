{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_cosine_schedule_with_warmup, AdamW\n",
    "from lightning.pytorch.utilities.types import (EVAL_DATALOADERS, STEP_OUTPUT,\n",
    "                                               TRAIN_DATALOADERS)\n",
    "import lightning as L\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.figure_factory as ff\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    multilabel_confusion_matrix,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from lightning.pytorch.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = '4_lightning'\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Направление</th>\n",
       "      <th>Факультет</th>\n",
       "      <th>ID студента</th>\n",
       "      <th>Оценка</th>\n",
       "      <th>Категория</th>\n",
       "      <th>Тег</th>\n",
       "      <th>Комментарий</th>\n",
       "      <th>Статус</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Видео</td>\n",
       "      <td>VP2</td>\n",
       "      <td>Видео лагает</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>113.0</td>\n",
       "      <td>5580.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ДЗ</td>\n",
       "      <td>H3 D</td>\n",
       "      <td>Торгом Бабаян! Спасибо вам большое за помощь в...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>126.0</td>\n",
       "      <td>5619.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ДЗ</td>\n",
       "      <td>H3</td>\n",
       "      <td>Спасибо)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E</td>\n",
       "      <td>123.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ДЗ</td>\n",
       "      <td>H2 E1</td>\n",
       "      <td>комментарий содержит нерелевантную информацию ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ДЗ</td>\n",
       "      <td>H3 D</td>\n",
       "      <td>Жонибек, хочу Вас поблагодарить за ваши советы...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56124</th>\n",
       "      <td>Z</td>\n",
       "      <td>133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ДЗ</td>\n",
       "      <td>H2</td>\n",
       "      <td>требуемый формат иконок платный</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56125</th>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1</td>\n",
       "      <td>заплатила и дальше просто никому нет дела поче...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56126</th>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Крайне раздражают некоторые детали)\\nНапример ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56127</th>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VC2 VP2</td>\n",
       "      <td>321.Профессия Бизнес-аналитик\\nАналитик данных...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56128</th>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VP2 VC2</td>\n",
       "      <td>Системный аналитик с нуля, 1-14 модули. Не нар...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56129 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Направление  Факультет  ID студента  Оценка Категория      Тег  \\\n",
       "0               C      113.0       1493.0     1.0     Видео      VP2   \n",
       "1               C      113.0       5580.0     5.0        ДЗ     H3 D   \n",
       "2               E      126.0       5619.0     5.0        ДЗ       H3   \n",
       "3               E      123.0        310.0     3.0        ДЗ    H2 E1   \n",
       "4               E      123.0       1913.0     5.0        ДЗ     H3 D   \n",
       "...           ...        ...          ...     ...       ...      ...   \n",
       "56124           Z      133.0          NaN     3.0        ДЗ       H2   \n",
       "56125           Z        NaN          NaN     0.0       NaN       S1   \n",
       "56126           Z        NaN          NaN     7.0       NaN      LMS   \n",
       "56127           Z        NaN          NaN     NaN       NaN  VC2 VP2   \n",
       "56128           Z        NaN          NaN     NaN       NaN  VP2 VC2   \n",
       "\n",
       "                                             Комментарий Статус  \n",
       "0                                           Видео лагает    NaN  \n",
       "1      Торгом Бабаян! Спасибо вам большое за помощь в...    NaN  \n",
       "2                                               Спасибо)    NaN  \n",
       "3      комментарий содержит нерелевантную информацию ...    NaN  \n",
       "4      Жонибек, хочу Вас поблагодарить за ваши советы...    NaN  \n",
       "...                                                  ...    ...  \n",
       "56124                    требуемый формат иконок платный    NaN  \n",
       "56125  заплатила и дальше просто никому нет дела поче...    NaN  \n",
       "56126  Крайне раздражают некоторые детали)\\nНапример ...    NaN  \n",
       "56127  321.Профессия Бизнес-аналитик\\nАналитик данных...    NaN  \n",
       "56128  Системный аналитик с нуля, 1-14 модули. Не нар...    NaN  \n",
       "\n",
       "[56129 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\vsevo\\MKN\\skillbox_nlp-vsevolod-lavrov\\data\\practice_cleaned.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "    df = df[['Категория', 'Комментарий']].dropna()\n",
    "    rename = {\n",
    "        'Категория': 'category',\n",
    "        'Комментарий': 'text'\n",
    "    }\n",
    "    df = df.rename(columns=rename)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        #df = process_data(df)\n",
    "\n",
    "        CLASSES = list(df['category'].unique())\n",
    "\n",
    "        labels = dict(zip(CLASSES, range(len(CLASSES))))\n",
    "       \n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "   \n",
    "            \n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "      \n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.texts[idx]\n",
    "        batch_y = np.array(self.labels[idx])\n",
    "        return batch_texts, batch_y\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(inputString):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    "    u\"\\U0001f926-\\U0001f937\"\n",
    "    u'\\U00010000-\\U0010ffff'\n",
    "    u\"\\u200d\"\n",
    "    u\"\\u2640-\\u2642\"\n",
    "    u\"\\u2600-\\u2B55\"\n",
    "    u\"\\u23cf\"\n",
    "    u\"\\u23e9\"\n",
    "    u\"\\u231a\"\n",
    "    u\"\\u3030\"\n",
    "    u\"\\ufe0f\"\n",
    "    u\"\\u2069\"\n",
    "    u\"\\u2066\"\n",
    "    u\"\\u200c\"\n",
    "    u\"\\u2068\"\n",
    "    u\"\\u2067\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vsevo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "def remove_rus_stopwords_func(text):\n",
    "    '''\n",
    "    Removes Stop Words (also capitalized) from a string, if present\n",
    "    \n",
    "    Args:\n",
    "        text (str): String to which the function is to be applied, string\n",
    "    \n",
    "    Returns:\n",
    "        Clean string without Stop Words\n",
    "    ''' \n",
    "    \n",
    "\n",
    "   \n",
    "    # check in lowercase \n",
    "    t = [token for token in text.split() if not token in set(stopwords.words(\"russian\"))]\n",
    "    text = ' '.join(t)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_collate_fn_t = Callable[[list[tuple[Tensor, Any]]], Any]\n",
    "\n",
    "\n",
    "class Datamodule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        datadir: Path,\n",
    "        tokenizer_path: Path,\n",
    "        batch_size: int,\n",
    "        num_workers: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.datadir = datadir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.test_size = 0.2\n",
    "        self.val_size = 0.2\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        df = pd.read_csv(self.datadir)\n",
    "\n",
    "        df = df[(df['Категория'] != \"Качество материалов\") & (df['Категория'] != \"Интерфейс платформы\") & (df['Категория'] != \"Общение с куратором\")]\n",
    "    \n",
    "        df = df[['Категория', 'Комментарий']].dropna()\n",
    "\n",
    "        df['Комментарий'] = df['Комментарий'].apply(lambda text: remove_rus_stopwords_func(text))\n",
    "\n",
    "        df['Комментарий'] = df['Комментарий'].apply(lambda text: remove_emoji(text))\n",
    "\n",
    "        df = df[df.Комментарий.apply(lambda x: len(x.split())) > 1]\n",
    "\n",
    "        df.drop_duplicates(inplace=True, subset=['Комментарий'])\n",
    "        \n",
    "        rename = {\n",
    "            'Категория': 'category',\n",
    "            'Комментарий': 'text'\n",
    "        }\n",
    "        df = df.rename(columns=rename)\n",
    "        \n",
    "        self.train, self.test = train_test_split(df, test_size=self.test_size, random_state=1337)\n",
    "        self.train, self.val = train_test_split(self.train, test_size=self.val_size, random_state=1337)\n",
    "    \n",
    "    @property\n",
    "    def collate_fn(self) -> _collate_fn_t | None:\n",
    "        return lambda batch: tuple(zip(*batch))\n",
    "        \n",
    "    def setup(self, stage: str) -> None:\n",
    "\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = CustomDataset(\n",
    "                self.train,\n",
    "                self.tokenizer\n",
    "            )\n",
    "            self.val_dataset = CustomDataset(\n",
    "                self.val,\n",
    "                self.tokenizer\n",
    "            )\n",
    "   \n",
    "        elif stage == \"validate\":\n",
    "            self.val_dataset = CustomDataset(\n",
    "                self.val,\n",
    "                self.tokenizer\n",
    "            )\n",
    "        elif stage == \"test\":\n",
    "            self.test_dataset = CustomDataset(\n",
    "                self.test,\n",
    "                self.tokenizer\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "     \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm = Datamodule(\"../data/practice_cleaned.csv\", 'cointegrated/rubert-tiny', 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm.prepare_data()\n",
    "# dm.setup(\"test\")\n",
    "# for batch in dm.test_dataset:\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lit(L.LightningModule):\n",
    "    def __init__(self, learning_rate, model_path, tokenizer_path, n_classes=4) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "        self.max_len = 512\n",
    "        self.out_features = self.model.bert.encoder.layer[1].output.dense.out_features\n",
    "        self.model.classifier = torch.nn.Linear(self.out_features, n_classes)\n",
    "        self.model = self.model\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: tuple[list[Tensor], list[dict[str, Tensor]]], batch_idx: int\n",
    "    ):\n",
    "        self.model.train()\n",
    "\n",
    "        train_input, train_label = batch\n",
    "       \n",
    "       \n",
    "        mask = train_input['attention_mask']\n",
    "        input_id = train_input['input_ids'].squeeze(1)\n",
    "        output = self.model(input_id, mask)\n",
    "\n",
    "        loss = self.loss(output[0], train_label.long())\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: tuple[Tensor, Tensor], batch_idx: int\n",
    "    ):\n",
    "       \n",
    "        train_input, train_label = batch\n",
    "      \n",
    "        \n",
    "        \n",
    "        \n",
    "        mask = train_input['attention_mask']\n",
    "        input_id = train_input['input_ids'].squeeze(1)\n",
    "        output = self.model(input_id, mask)\n",
    "\n",
    "        # print(train_label.shape, output[0].shape)\n",
    "        f1 = F1Score(task=\"multiclass\", num_classes=4, average='macro').to('cuda')\n",
    "        \n",
    "        score = f1(output[0], train_label).to('cuda')\n",
    "\n",
    "        self.log('val_f1_score', score)\n",
    "        \n",
    "        return {\n",
    "            \"f1_score\": score,\n",
    "        }\n",
    "    \n",
    "    def test_step(\n",
    "        self, batch: tuple[Tensor, Tensor], batch_idx: int\n",
    "    ):\n",
    "   \n",
    "        train_input, train_label = batch\n",
    "      \n",
    "        mask = train_input['attention_mask']\n",
    "        input_id = train_input['input_ids'].squeeze(1)\n",
    "        output = self.model(input_id, mask)\n",
    "       \n",
    "        score = f1_score(train_label, output, average='macro')        \n",
    "\n",
    "        self.log('test_f1_score', score)\n",
    "        \n",
    "        return {\n",
    "            \"f1_score\": score,\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": torch.optim.lr_scheduler.MultiStepLR(\n",
    "                optimizer, milestones=[5, 10, 15]\n",
    "            )\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "lit_module = Lit(\n",
    "    learning_rate=0.001,\n",
    "    model_path='cointegrated/rubert-tiny',\n",
    "    tokenizer_path='cointegrated/rubert-tiny'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=4,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = Datamodule(\n",
    "    Path(\"../data/practice_cleaned.csv\"),\n",
    "    'cointegrated/rubert-tiny',\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('cointegrated/rubert-tiny')\n",
    "out_features = model.bert.encoder.layer[1].output.dense.out_features\n",
    "model.classifier = torch.nn.Linear(out_features, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for batch in datamodule.train_dataloader():\n",
    "#     train_input, train_label = batch\n",
    "\n",
    "#     mask = train_input['attention_mask']\n",
    "#     input_id = train_input['input_ids'].squeeze(1)\n",
    "#     output = model(input_id, mask)\n",
    "\n",
    "#     # print(train_label.shape, output[0].shape)\n",
    "#     f1 = F1Score(task=\"multiclass\", num_classes=4, average='macro')\n",
    "    \n",
    "#     score = f1(output[0], train_label)  \n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                          | Params\n",
      "--------------------------------------------------------\n",
      "0 | model | BertForSequenceClassification | 11.8 M\n",
      "1 | loss  | CrossEntropyLoss              | 0     \n",
      "--------------------------------------------------------\n",
      "11.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.8 M    Total params\n",
      "47.142    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6f731c18144325a177f8abca1e913e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vsevo\\MKN\\skillbox-practice-vsevolod-lavrov\\.pixi\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\vsevo\\MKN\\skillbox-practice-vsevolod-lavrov\\.pixi\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8bde2ce78c4dfdb8e9c2edf77e53f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec754cd6ae8418da8eb72f719ed5330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0ad6c3433344fda1b53529a71d3087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c9abb2f2ed4c80a8dcd858c7859293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75f17d7f49646a9852c347818b3bc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=lit_module,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(logits: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"Helper function for predictions calculating.\n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): model's raw output\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: array with predicted class id.\n",
    "    \"\"\"\n",
    "    s = torch.nn.Softmax()\n",
    "    probs = s(torch.tensor(logits))\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [22:35<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "datamodule.setup(stage=\"test\")\n",
    "\n",
    "preds_logits = torch.tensor([])\n",
    "targets = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for val_input, val_label in tqdm(datamodule.test_dataloader()):\n",
    "        mask = val_input['attention_mask']\n",
    "        input_id = val_input['input_ids'].squeeze(1)\n",
    "        output = lit_module.model(input_id, mask)[0]\n",
    "        preds_logits = torch.cat((preds_logits, output))\n",
    "        targets = torch.cat((targets, val_label.long().cpu()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vsevo\\MKN\\skillbox-practice-vsevolod-lavrov\\.pixi\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preds = np.apply_along_axis(predict, 1, preds_logits)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1.,  ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score      support\n",
      "0              0.440797  0.988433  0.609697  3804.000000\n",
      "1              0.520408  0.012213  0.023865  4176.000000\n",
      "2              0.000000  0.000000  0.000000   262.000000\n",
      "3              0.000000  0.000000  0.000000   386.000000\n",
      "accuracy       0.441701  0.441701  0.441701     0.441701\n",
      "macro avg      0.240301  0.250161  0.158391  8628.000000\n",
      "weighted avg   0.446224  0.441701  0.280360  8628.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vsevo\\MKN\\skillbox-practice-vsevolod-lavrov\\.pixi\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\vsevo\\MKN\\skillbox-practice-vsevolod-lavrov\\.pixi\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\vsevo\\MKN\\skillbox-practice-vsevolod-lavrov\\.pixi\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(targets, preds, target_names=CLASSES, output_dict=True)\n",
    "cr = pd.DataFrame(cr).T\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(\n",
    "#     model=lit_module,\n",
    "#     datamodule=datamodule,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
